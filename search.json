[{"title":"2019_cvpr_and_iccv","url":"/2019/10/01/2019-cvpr-and-iccv/","content":"\n# CVPR 2019 - dehaze\n\n1、[Dual Residual Networks Leveraging the Potential of Paired Operations for Image Restoration](https://arxiv.org/pdf/1903.08817.pdf)\n\n作者：Xing Liu， Masanori Suganuma， Zhun Sun，Takayuki Okatani，Graduate School of Information Sciences, Tohoku University\n\n2、[Enhanced Pix2pix Dehazing Network](http://openaccess.thecvf.com/content_CVPR_2019/papers/Qu_Enhanced_Pix2pix_Dehazing_Network_CVPR_2019_paper.pdf)\n\n作者：Yanyun Qu (XMU)*; Yizi Chen (XMU); Jingying Huang (XMU); Yuan Xie (East China Normal University)\n\n3、[PMS-Net: Robust Haze Removal Based on Patch Map for Singe Images](http://openaccess.thecvf.com/content_CVPR_2019/papers/Qu_Enhanced_Pix2pix_Dehazing_Network_CVPR_2019_paper.pdf)\n\n作者：Wei-Ting Chen (National Taiwan University)*; Jian-Jiun Ding (Nil); Sy-Yen Kuo (National Taiwan University)\n\n","tags":["TODO"]},{"title":"Map-Reduce程序模板","url":"/2019/01/06/Map-Reduce程序模板/","content":"# 模板\n```\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.DoubleWritable;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Partitioner;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\npublic class ClassName\n{\n\t// Map函数\n\tpublic static class MapClass extends Mapper<k1, v1, k2, v2>\n\t  {\n\t    //TODO\n\t    \n\t    public void map(k1 key, v1 value, Context context) throws IOException, InterruptedException \n\t    {\n\t      \n          /*\n          * TODO: context.write(key, value);//写输出结果\n          */\n\n\t    }\n\t  }\n\t\n\t/*\n\t * Partition函数\n\t * 实现将Map阶段的输出结果按指定的方法分到不同的分区中，为reduce阶段做准备\n\t */\n\tpublic static class PartitionClass extends Partitioner<k1,v1>\n\t  {\n\t    public int getPartition(k1 key, k1 value, int numPartitions) //numPartitions参数值从主函数中的job.setNumReduceTasks(26)获得\n\t    {\n\t        /*\n          * TODO: context.write(key, value);//写输出结果\n          */\n\t    }\n\t  }\n\t\n\t/*\n\t * Combiner函数\n\t * 重载了默认的Reduce方法，通过key遍历其values<Iterator>, 并加以处理 \n\t */\n\tpublic static class CombinerClass extends Reducer<k1,v1,k2,v2> \n\t  {\n\t    //TODO\n\t    public void reduce(k1 key, Iterable<v1> values,Context context) throws IOException, InterruptedException \n\t    {\n\t        \n\t        /*\n          * TODO: context.write(key, value);//写输出结果\n          */\n\t    }\n\t  }\n\t\n\t\n\t/*\n\t * Reduce函数\n\t */\n\tpublic static class ReduceClass extends Reducer<k1,v1,k2,v2> \n\t  {\n\t\t//TODO\n\t      public void reduce(k1 key, Iterable<v1> values,Context context) throws IOException, InterruptedException \n\t      {\n\t         /*\n              * TODO: context.write(key, value);//写输出结果\n              */\n\t      }\n\t      protected void cleanup(Context context) throws IOException, InterruptedException \n\t      {\n\t        /*\n             * TODO: context.write(key, value);//写输出结果\n             */\n\t      }  \n\n\t  }\n\t\n\t/*\n\t * 作业提交\n\t */\n\tpublic static void main(String[] args) throws Exception \n\t  {\n\t    Configuration conf = new Configuration();//启用默认设置,Configuration对象封装了客户端服务器的配置\n\t    String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();//获取主函数参数\n\t    if (otherArgs.length != 2) \n\t    {\n\t      System.err.println(\"Usage: ClassName <in> <out>\");\n\t      System.exit(2);\n\t    }\n\n\t    Job job = Job.getInstance(conf);//定义一个作业控制\n        // 替换为你的类\n\t    job.setJarByClass(ClassName.class);//设置执行类\n\t    job.setNumReduceTasks(10);//定义多少个reduce\n\n\t    job.setMapperClass(MapClass.class);//指定map类型\n\t    job.setCombinerClass(CombinerClass.class);//指定combiner类型\n\t    job.setReducerClass(ReduceClass.class);//指定reduce类型\n\t    job.setPartitionerClass(PartitionClass.class);//指定partition类型\n\n        //设置输出类型\n\t    job.setMapOutputKeyClass(Text.class);//map的输出key类型设置\n\t    job.setMapOutputValueClass(IntWritable.class);//map的输出value类型设置\n\n\t    //**注意**：没有job.setReduceOutputKeyClass\n\t    job.setOutputKeyClass(Text.class);//设置**最终**的输出类型是Text（有些MapReduce程序是没有Reduce部分的）\n\t    job.setOutputValueClass(DoubleWritable.class);//设置最终的输出类型是DoubleWritable\n\n\n\t    //定义输入数据的路径，通过Debug Configuration的Argument设置，该路径可以是单个文件，也可以是目录，此时将目录下所有文件当作输入或符合特定文件模式的一组文件\n\t    FileInputFormat.addInputPath(job, new Path(otherArgs[0]));\n\t    //定义输出数据的路径，通过Debug Configuration的Argument设置，在运行任务前该目录不能存在，否则会报错\n\t    FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));\n\t    //每次配置Job的最后一步，System.exit（0）代表正常退出，System.exit(1)代表不正常退出\n\n\t    //作业提交就是这一句：job.waitForCompletion(true)，其含义是提交作业后并监控集群，作业完成后及时获得反馈信息，若作业正常完成就返回0，否则就返回1。\n\t    System.exit(job.waitForCompletion(true) ? 0 : 1);\n\t  }\n\t\n}\n\n```\n\n# 注意：\n- 上面的类型参数在各个类中都需要对应上，比如Map的输出<k2, v2>需要对应上Reduce的输入<k1, v1>\n- 使用时根据数据的类型修改类型参数和具体操作代码","tags":["hadoop"]},{"title":"非Root用户无法显示jps结果","url":"/2018/12/10/非Root用户无法显示jps结果/","content":"#### 一、问题描述\n非root用户执行jps命令时不显示结果，如图：\n{% asset_img 1.jpg 非Root用户无法显示jps结果 %}\n#### 二、原因分析\njps需要在tmp下创建一个hsperfdata_username的目录，用来存放进程的ip，所以检查一下/tmp/hsperfdata_username是否存在，如果不存在则自己创建一个，然后再检查权限。\n{% asset_img 2.jpg 非Root用户无法显示jps结果 %}\n\n可以看出无法显示的原因是权限。\n#### 三、解决方案\n修改文件权限：\n```\nchown -R hadoop.hadoop /tmp/hsperfdata_hadoop\n```\n{% asset_img 3.jpg 非Root用户无法显示jps结果 %}\n#### 四、效果\n{% asset_img 4.jpg 非Root用户无法显示jps结果 %}","tags":["Linux"]},{"title":"启动集群后Slave无法启动DataNode进程","url":"/2018/10/09/启动集群后Slave无法启动DataNode进程/","content":"\n#### 一、问题描述\n执行start-all.sh后，slave进程中没有DataNode\n#### 二、问题查看\n去Slave的/hadoop/logs文件查看日志，信息如下：\n{% asset_img 报错信息.jpg 启动集群后Slave无法启动DataNode进程 %}\n\n表明：造成无法启动DataNode进程的原因是namenode的clusterID和datanode的clusterID不匹配，一般造成这种问题的原因是多次执行了namenode格式化命令：\n```\nhdfs namenode -format\n```\nok,直接分别去查看响应的文件是否真的如此：\n\n###### 1.查看slave：\n{% asset_img slave截图.jpg 启动集群后Slave无法启动DataNode进程 %}{% asset_img slave-version.jpg 启动集群后Slave无法启动DataNode进程 %}\n###### 2.查看master:\n{% asset_img master截图.jpg 启动集群后Slave无法启动DataNode进程 %}{% asset_img master-version.jpg 启动集群后Slave无法启动DataNode进程 %}\n__ps:对比红色线框内容即可，图中为已修改完成的结果，二者一致即可！__\n\n#### 三、结果\n\n重新执行start-all.sh命令，然后在slave执行jps，结果如下：\n{% asset_img 结果.jpg 启动集群后Slave无法启动DataNode进程 %}\n\n恢复正常:)\n","tags":["hadoop"]},{"title":"重装系统后恢复hexo","url":"/2018/08/16/重装系统后恢复hexo/","content":"### 适用情况：\n- 重装了系统/换台电脑\n- 保存了原来部署的hexo文件  \n  \n原来的部署文件如下图：\n{% asset_img hexo1.jpg 重装系统后恢复hexo %}\n\n### 准备工作\n1. 安装git\n    + [Git下载](https://git-scm.com/)\n2. 配置SSH key\n   + 在\"C:\\Users\\username\"下运行git bash\n   + 运行如下命令：\n    ```\n    ssh-keygen -t rsa -C xxxx(你的email) # 一直enter\n    ```\n   + 结束后会看到目录生成了.ssh文件\n   + 在github添加新的SSH key\n   + Settings -> SSH and GPG keys -> new SSH key\n   + 在Key文本框里粘贴公钥id_rsa.pub文件的内容(注意后缀！这是公钥)\n   + 最后点击Add SSH Key\n  \n3. 安装Nodejs\n   + [Nodejs下载](https://nodejs.org/en/)\n4. 安装hexo\n   + 打开git bash,运行如下命令:\n   ```\n    npm install hexo-cli -g\n   ```\n\n### 具体步骤\n1. 复制以下文件到新的目录\n\n{% asset_img hexo2.jpg 重装系统后恢复hexo %} \n\n(ps：其中蓝色框文件为.gitignore文件,如果没看到可以查看隐藏文件)\n\n\n2. 在新拷贝的文件夹中打开git bash,运行以下命令：\n    ```\n    npm install # 安装模块\n    ```\n(ps:不要用hexo init 命令，这个命令会重置站点的配置文件_config.yml的内容:p)\n\n3. 安装其他插件：\n   + 部署到git的插件：\n    ```\n    npm install hexo-deployer-git --save\n    ```\n   + others...\n4. 生成和部署：\n   ```\n    hexo g\n    hexo d\n   ```\n5. 预览:\n   ```\n    hexo s\n   ```\n   在[http://localhost:4000/](http://localhost:4000/)查看效果\n\n   hexo 部署文件最后如图所示：\n   {% asset_img hexo3.jpg 重装系统后恢复hexo %}  \n\n  <center>---end---</center>\n\n\n\n","tags":["system"]},{"title":"hello world","url":"/2018/04/05/hello-world/","content":"### glassy:\n\n之前的blog因为忘了备份全部丢失 = =\n\n其实也没什么可供输出的，丢失了就丢失了，现在打算重新维护\n\n另外简书也懒得搬运了，毕竟，没什么可供输出哇 :)\n\n总之，欢迎来到glassy的blog\n\nlink start !","tags":["about-me"]}]